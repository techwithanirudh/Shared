{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Toonify yourself Flask",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techwithanirudh/Shared/blob/master/Toonify_yourself_Flask_Done_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc"
      },
      "source": [
        "# Toonify yourself!\n",
        "\n",
        "Please ensure that you're using a GPU runtime\n",
        "\n",
        "First some setup:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IppG8Z8O19R"
      },
      "source": [
        "## Upload your own photos\n",
        "\n",
        "Upload your photos to `raw/`. These don't need to be aligned as we'll use a face detector to grab all the faces and transform them into the correct format. One note of caution is that you'll need a pretty high-resolution picture of a face to get a sharp result (the final face crop is resized to 1024x1024 pixels)\n",
        "\n",
        "We'll grab a example image from the internet to work with.\n",
        "\n",
        "The basic process is:\n",
        "- Extract faces and align the images\n",
        "- Project the images (i.e. find the latent code)\n",
        "- Toonify the images (i.e. use the latent code with the toon model)\n",
        "\n",
        "Results will be placed in the stylegan2/generated folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-2oM_L8VWYZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af0356d-b906-4c1a-e633-35cf5f7a2694"
      },
      "source": [
        "# !wget https://upload.wikimedia.org/wikipedia/commons/6/6d/Shinz%C5%8D_Abe_Official.jpg -O raw/example.jpg\r\n",
        "# from google.colab import files\r\n",
        "# import os\r\n",
        "\r\n",
        "# os.chdir('/content/stylegan2/raw')\r\n",
        "\r\n",
        "# uploaded = files.upload()\r\n",
        "# for filename in uploaded.keys():\r\n",
        "#   print('User uploaded file \"{name}\" with {length} bytes'.format(name=filename, length=len(uploaded[filename])))\r\n",
        "\r\n",
        "# os.chdir('/content/stylegan2')\r\n",
        "\r\n",
        "# main_helper.py -->\r\n",
        "# import pretrained_networks\r\n",
        "# import numpy as np\r\n",
        "# from PIL import Image\r\n",
        "# import dnnlib\r\n",
        "# import dnnlib.tflib as tflib\r\n",
        "# from pathlib import Path\r\n",
        "# from IPython import get_ipython\r\n",
        "\r\n",
        "# # use my copy of the blended model to save Doron's download bandwidth\r\n",
        "# # get the original here https://mega.nz/folder/OtllzJwa#C947mCCdEfMCRTWnDcs4qw\r\n",
        "# blended_url = \"https://drive.google.com/uc?id=1H73TfV5gQ9ot7slSed_l-lim9X7pMRiU\" \r\n",
        "# ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\r\n",
        "\r\n",
        "# _, _, Gs_blended = pretrained_networks.load_networks(blended_url)\r\n",
        "# print(Gs_blended)\r\n",
        "# _, _, Gs = pretrained_networks.load_networks(ffhq_url)  \r\n",
        "\r\n",
        "# latent_dir = Path(\"generated\")\r\n",
        "# latents = latent_dir.glob(\"*.npy\")\r\n",
        "# for latent_file in latents:\r\n",
        "#   latent = np.load(latent_file)\r\n",
        "#   latent = np.expand_dims(latent,axis=0)\r\n",
        "#   synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\r\n",
        "#   print(Gs_blended)\r\n",
        "#   images = Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\r\n",
        "#   Image.fromarray(images.transpose((0,2,3,1))[0], 'RGB').save(latent_file.parent / (f\"{latent_file.stem}-toon.jpg\"))\r\n",
        "# <--\r\n",
        "\r\n",
        "# templates/index.html -->\r\n",
        "# <!DOCTYPE html>\r\n",
        "# <html>\r\n",
        "# <head>\r\n",
        "#     <title>Index</title>\r\n",
        "# </head>\r\n",
        "# <body>\r\n",
        "#     <img src=\"{{ image }}\" alt=\"Image\">\r\n",
        "# </body>\r\n",
        "# </html>\r\n",
        "# <--\r\n",
        "\r\n",
        "# %tensorflow_version 1.x\r\n",
        "# !git clone https://github.com/justinpinkney/stylegan2\r\n",
        "# %cd stylegan2\r\n",
        "# !nvcc test_nvcc.cu -o test_nvcc -run\r\n",
        "# !mkdir raw\r\n",
        "# !mkdir aligned\r\n",
        "# !mkdir generated\r\n",
        "\r\n",
        "!pip install flask-ngrok\r\n",
        "from flask import Flask, render_template, request\r\n",
        "import os\r\n",
        "from flask_ngrok import run_with_ngrok\r\n",
        "import base64\r\n",
        "from werkzeug.utils import secure_filename\r\n",
        "\r\n",
        "GENERATED_FOLDER = '/content/stylegan2/generated'\r\n",
        "app = Flask(__name__)\r\n",
        "app.config['UPLOAD_FOLDER'] = GENERATED_FOLDER\r\n",
        "run_with_ngrok(app)\r\n",
        "\r\n",
        "@app.route('/path/<filenm>/compute', methods=['POST'])\r\n",
        "def getFile(filenm):\r\n",
        "  global filename\r\n",
        "  filename = secure_filename(filenm)\r\n",
        "  print(filename)\r\n",
        "  imgdata = request.get_data()\r\n",
        "  print(type(imgdata))\r\n",
        "  imgdata = base64.b64decode(imgdata)\r\n",
        "  with open(f'/content/stylegan2/raw/{filename}', 'wb') as f:\r\n",
        "    f.write(imgdata)\r\n",
        "  path = compute()\r\n",
        "  return render_template(\"/content/stylegan2/templates/index.html\", image=path)\r\n",
        "\r\n",
        "def mainHelp():\r\n",
        "  get_ipython().system('python align_images.py raw aligned')\r\n",
        "  get_ipython().system('python project_images.py --num-steps 500 aligned generated')\r\n",
        "  get_ipython().system('python main_helper.py')\r\n",
        "\r\n",
        "def compute():\r\n",
        "  os.chdir('/content/stylegan2')\r\n",
        "  import pretrained_networks\r\n",
        "  import numpy as np\r\n",
        "  from PIL import Image\r\n",
        "  import dnnlib\r\n",
        "  import dnnlib.tflib as tflib\r\n",
        "  from pathlib import Path\r\n",
        "  mainHelp()\r\n",
        "  from IPython.display import Image \r\n",
        "  filenameO = filename.split('.')[0]\r\n",
        "  embedded = Image(filename=f\"generated/{filenameO}_01.png\", width=256)\r\n",
        "  display(embedded)\r\n",
        "  tooned = Image(filename=f\"generated/{filenameO}_01-toon.jpg\", width=256)\r\n",
        "  display(tooned)\r\n",
        "  \r\n",
        "  os.remove(f'generated/{filenameO}_01-toon.jpg')\r\n",
        "  os.remove(f'generated/{filenameO}_01.png')\r\n",
        "  os.remove(f'generated/{filenameO}_01.npy')\r\n",
        "  os.remove(f'aligned/{filenameO}_01.png')\r\n",
        "  os.remove(f'raw/{filename}')\r\n",
        "  return f\"generated/{filenameO}_01-toon.jpg\"\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://2c123cd35a70.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "face.png\n",
            "<class 'bytes'>\n",
            "Loading networks from \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n",
            "Loading images from \".stylegan2-tmp/dataset/images\"\n",
            "detected 1 images ...\n",
            "Creating dataset \".stylegan2-tmp/dataset/tfrecords\"\n",
            "Adding the images to tfrecords ...\n",
            "added images 0\n",
            "Added 1 images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnCqZFiNLCVI",
        "outputId": "f9f0c4c9-5783-4fba-c0f7-c3578733eb4a"
      },
      "source": [
        "import os\r\n",
        "print(os.environ)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "environ({'NO_GCE_CHECK': 'True', 'GCS_READ_CACHE_BLOCK_SIZE_MB': '16', 'CLOUDSDK_CONFIG': '/content/.config', '__EGL_VENDOR_LIBRARY_DIRS': '/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/', 'CUDA_VERSION': '10.1.243', 'PATH': '/tensorflow-1.15.2/python3.6/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin', 'HOME': '/root', 'LD_LIBRARY_PATH': '/usr/lib64-nvidia', 'LANG': 'en_US.UTF-8', 'SHELL': '/bin/bash', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'CUDA_PKG_VERSION': '10-1=10.1.243-1', 'SHLVL': '0', 'GCE_METADATA_TIMEOUT': '0', 'NCCL_VERSION': '2.7.8', 'NVIDIA_VISIBLE_DEVICES': 'all', 'DEBIAN_FRONTEND': 'noninteractive', 'CUDNN_VERSION': '7.6.5.32', 'LAST_FORCED_REBUILD': '20201217', 'JPY_PARENT_PID': '62', 'PYTHONPATH': '/tensorflow-1.15.2/python3.6:/env/python', 'DATALAB_SETTINGS_OVERRIDES': '{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\\\"172.28.0.2\\\\\"\"]}', 'ENV': '/root/.bashrc', 'GLIBCXX_FORCE_NEW': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'TF_FORCE_GPU_ALLOW_GROWTH': 'true', 'LD_PRELOAD': '/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4', 'NVIDIA_REQUIRE_CUDA': 'cuda>=10.1 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419', 'OLDPWD': '/', 'HOSTNAME': 'b42b963078e6', 'COLAB_GPU': '1', 'PWD': '/', 'CLOUDSDK_PYTHON': 'python3', 'GLIBCPP_FORCE_NEW': '1', 'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command', 'TBE_CREDS_ADDR': '172.28.0.1:8008', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcFV64xZCSRc"
      },
      "source": [
        "import os \r\n",
        "os.chdir('/content/stylegan2')\r\n",
        "\r\n",
        "import pretrained_networks\r\n",
        "\r\n",
        "# use my copy of the blended model to save Doron's download bandwidth\r\n",
        "# get the original here https://mega.nz/folder/OtllzJwa#C947mCCdEfMCRTWnDcs4qw\r\n",
        "blended_url = \"https://drive.google.com/uc?id=1H73TfV5gQ9ot7slSed_l-lim9X7pMRiU\" \r\n",
        "ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\r\n",
        "\r\n",
        "_, _, Gs_blended = pretrained_networks.load_networks(blended_url)\r\n",
        "_, _, Gs = pretrained_networks.load_networks(ffhq_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcWXgS5DXata",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "ab5feb70-9ba7-4933-9534-8d3e93ba2e05"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from pathlib import Path\n",
        "\n",
        "latent_dir = Path(\"generated\")\n",
        "latents = latent_dir.glob(\"*.npy\")\n",
        "for latent_file in latents:\n",
        "  latent = np.load(latent_file)\n",
        "  latent = np.expand_dims(latent,axis=0)\n",
        "  synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "  images = Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\n",
        "  Image.fromarray(images.transpose((0,2,3,1))[0], 'RGB').save(latent_file.parent / (f\"{latent_file.stem}-toon.jpg\"))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-077ea0c9d4a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0msynthesis_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_images_to_uint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnchw_to_nhwc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGs_blended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynthesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomize_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msynthesis_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf\"{latent_file.stem}-toon.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/stylegan2/dnnlib/tflib/network.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, input_transform, output_transform, return_as_list, print_progress, minibatch_size, num_gpus, assume_frozen, *in_arrays, **dynamic_kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mmb_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmb_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmb_begin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mmb_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmb_begin\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmb_end\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmb_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mmb_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmb_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmb_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'run'"
          ]
        }
      ]
    }
  ]
}