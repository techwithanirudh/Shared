{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toonify yourself Flask",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techwithanirudh/Shared/blob/master/Toonify_yourself_FlaskAlmost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc"
      },
      "source": [
        "# Toonify yourself!\n",
        "\n",
        "Please ensure that you're using a GPU runtime\n",
        "\n",
        "First some setup:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIJHDihQja38",
        "outputId": "365de1af-ea2d-4efc-c947-0438dbc2ccd0"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzDuIoMcqfBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39ae95e-3603-428a-ae88-6109d8b21358"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "!git clone https://github.com/justinpinkney/stylegan2\r\n",
        "%cd stylegan2\r\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\r\n",
        "!mkdir raw\r\n",
        "!mkdir aligned\r\n",
        "!mkdir generated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Total 269 (delta 0), reused 0 (delta 0), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (269/269), 2.32 MiB | 30.07 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n",
            "/content/stylegan2\n",
            "CPU says hello.\n",
            "GPU says hello.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IppG8Z8O19R"
      },
      "source": [
        "## Upload your own photos\n",
        "\n",
        "Upload your photos to `raw/`. These don't need to be aligned as we'll use a face detector to grab all the faces and transform them into the correct format. One note of caution is that you'll need a pretty high-resolution picture of a face to get a sharp result (the final face crop is resized to 1024x1024 pixels)\n",
        "\n",
        "We'll grab a example image from the internet to work with.\n",
        "\n",
        "The basic process is:\n",
        "- Extract faces and align the images\n",
        "- Project the images (i.e. find the latent code)\n",
        "- Toonify the images (i.e. use the latent code with the toon model)\n",
        "\n",
        "Results will be placed in the stylegan2/generated folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-2oM_L8VWYZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "95e34f8f-2e46-43bc-8d35-4af83c2a7530"
      },
      "source": [
        "# !wget https://upload.wikimedia.org/wikipedia/commons/6/6d/Shinz%C5%8D_Abe_Official.jpg -O raw/example.jpg\r\n",
        "# from google.colab import files\r\n",
        "# import os\r\n",
        "\r\n",
        "# os.chdir('/content/stylegan2/raw')\r\n",
        "\r\n",
        "# uploaded = files.upload()\r\n",
        "# for filename in uploaded.keys():\r\n",
        "#   print('User uploaded file \"{name}\" with {length} bytes'.format(name=filename, length=len(uploaded[filename])))\r\n",
        "\r\n",
        "# os.chdir('/content/stylegan2')\r\n",
        "from google.colab.output import eval_js\r\n",
        "print('URL: ' + eval_js('google.colab.kernel.proxyPort(5000)') + '/path/drive/MyDrive-face.png/compute')\r\n",
        "\r\n",
        "from flask import Flask, render_template\r\n",
        "import os\r\n",
        "\r\n",
        "GENERATED_FOLDER = '/content/stylegan2/generated'\r\n",
        "app = Flask(__name__)\r\n",
        "app.config['UPLOAD_FOLDER'] = GENERATED_FOLDER\r\n",
        "\r\n",
        "@app.route('/path/drive/<path_to_file>/compute')\r\n",
        "def getFile(path_to_file):\r\n",
        "  global filename\r\n",
        "  path_to_file = path_to_file.replace('-', '/')\r\n",
        "  filename = path_to_file.split('/')\r\n",
        "  filename = filename[len(filename) - 1]\r\n",
        "  print(filename)\r\n",
        "\r\n",
        "  with open(f'/content/drive/{path_to_file}', 'rb') as fileData:\r\n",
        "    open(f'/content/stylegan2/raw/{filename}', 'a')\r\n",
        "    with open(f'/content/stylegan2/raw/{filename}', 'wb') as fileWrite:\r\n",
        "      fileWrite.write(fileData.read())\r\n",
        "\r\n",
        "  compute()\r\n",
        "\r\n",
        "def compute():\r\n",
        "  os.chdir('/content/stylegan2')\r\n",
        "  import pretrained_networks\r\n",
        "  import numpy as np\r\n",
        "  from PIL import Image\r\n",
        "  import dnnlib\r\n",
        "  import dnnlib.tflib as tflib\r\n",
        "  from pathlib import Path\r\n",
        "  from IPython.display import Image \r\n",
        "\r\n",
        "  # use my copy of the blended model to save Doron's download bandwidth\r\n",
        "  # get the original here https://mega.nz/folder/OtllzJwa#C947mCCdEfMCRTWnDcs4qw\r\n",
        "  blended_url = \"https://drive.google.com/uc?id=1H73TfV5gQ9ot7slSed_l-lim9X7pMRiU\" \r\n",
        "  ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\r\n",
        "\r\n",
        "  _, _, Gs_blended = pretrained_networks.load_networks(blended_url)\r\n",
        "  _, _, Gs = pretrained_networks.load_networks(ffhq_url)  \r\n",
        "  !python align_images.py raw aligned\r\n",
        "  !python project_images.py --num-steps 500 aligned generated\r\n",
        "\r\n",
        "  latent_dir = Path(\"generated\")\r\n",
        "  latents = latent_dir.glob(\"*.npy\")\r\n",
        "  for latent_file in latents:\r\n",
        "    latent = np.load(latent_file)\r\n",
        "    latent = np.expand_dims(latent,axis=0)\r\n",
        "    synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\r\n",
        "    images = Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\r\n",
        "    Image.fromarray(images.transpose((0,2,3,1))[0], 'RGB').save(latent_file.parent / (f\"{latent_file.stem}-toon.jpg\"))\r\n",
        "  embedded = Image(filename=f\"generated/{filename}_01.png\", width=256)\r\n",
        "  display(embedded)\r\n",
        "  tooned = Image(filename=f\"generated/{filename}_01-toon.jpg\", width=256)\r\n",
        "  display(tooned)\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    app.run(host='0.0.0.0', port=5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "URL: https://d84tixt6f6n-496ff2e9c6d22116-5000-colab.googleusercontent.com//path/drive/MyDrive-face.png/compute\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "face.png\n",
            "Downloading https://drive.google.com/uc?id=1H73TfV5gQ9ot7slSed_l-lim9X7pMRiU .... done\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}